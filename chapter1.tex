\chapter{INTRODUCTION}

The scientific process increasingly benefits from the use of computation to achieve advances faster. Many times these computations can be naturally broken into steps, where each step may filter, transform or compute on the data it receives as input from another step.  Workflows have emerged as a paradigm for representing these computations. Many seminal works on the topic of workflow managing systems began to appear in the mid 2000's\cite{yu2005taxonomy, fox2006special, gil2007examining}, and many workflow systems were developed, such as the e-Science project\cite{deelman2009workflows}, Kepler\cite{altintas2004kepler} and Taverna\cite{oinn2006taverna}.  

The scale of computations have been growing with time, and the ability of the systems cited above to process large amounts of data and to execute the placement of task execution on a distributed environment is still very limited.  Pegasus\cite{singh2008workflow} is a more recent workflow management system for scientific applications.  It enables workflows to be executed both locally and on a cluster of computers in a simultaneous manner.  It has a rich set of APIs that allow the construction and representation of workflows as Directed Acyclic Graphs (DAGs).  It also has more advanced job scheduling and monitoring facilities than previous systems.  But still, it cannot meet the scalability demands of today's scientific computations.  

Orthogonal to the development of workflow management systems, many distributed systems have been designed and developed to meet the growing demands of computation.  One of such systems is Apache Hadoop, which is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Apache Oozie\cite{islam2012oozie} is Apache Hadoop's workflow and scheduling system.  Its workflow definition API rivals that of Pegasus, while it takes advantage of the superior scalability of Hadoop.


\section{Our contributions}
Chapter \ref{chap:foundational} of our discussion is also a great contribution to the topic of scientific workflows, since it contains a throughout explanation of the tradeoffs and balancing acts that need to be addressed (or at least considered) when designing a system that promises a functionality similar to the one we are attempting in our project. The system that I have designed and implemented is tied to a specific technology of today, the Hadoop ecosystem.  And as Hadoop goes, so goes my system.  But the discussions of Chapter \ref{chap:foundational} will still remain relevant for years to come.
