\chapter{IMPLEMENTATION OF THE SYSTEM}
\label{chap:implementation}
\section{Birdeye overview}
Introduce the system and what it does. To the point that it takes you to the Hadoop ecosystem and
how it uses it
\subsection{The Hadoop ecosystem}
\subsection{Configuration parameters}
Talk about the configuration parameters used for the system such as namenode, oozieurl, etc.

\section{The Workflow Definition Language}
We have chosen the JSON format for the definition of workflows because its expressiveness is sufficient for what we need, and it is also very human readable. As shown in Figure \ref{fig:workflow_definition_language}, a workflow is made of a \textbf{name}, an \textbf{start action id}, an \textbf{end action id} and a \textbf{list of actions}. 

\begin{figure}
\begin{mdframed}
\begin{singlespace}
\begin{verbatim}


{
    "name": "Example Workflow",
    "startActionId": 1,
    "endActionId": 2,
    "actions": [
        {
            "id": 1,
            "name": "action1-name",
            "type": "command-line",
            .
            .
            .
        },
        {
            "id": 2,
            "name": "action1-name",
            "parentActions": [
                { 
                    "id": 1,
                }
            ],
            "type": "command-line",
            .
            .
            .
        }
    ]
}
\end{verbatim}
\end{singlespace}
\end{mdframed}
\caption{Workflow definition}
\label{fig:workflow_definition_language}
\end{figure}

The workflow definition in Figure \ref{fig:workflow_definition_language} consists of two actions whose ids are 1 and 2 where action with id 2 must be executed after action with id id finishes. This is expressed by making action 1 a parent of action 2. Among the constraints that are imposed by the system we have the following:

\begin{enumerate}
\item A workflow most have at least one action.
\item No two actions can have one same id in a workflow definition.
\item If an action \textit{id} is referenced somewhere in the workflow definition (they can be referenced in \textit{startActionId}, \textit{endActionId}, and within the array of \textit{parentActions}), that action must be defined in the array of actions of the workflow.
\item The \textit{parentActions} attribute of an action will define relationships among the actions that can be represented as a directed graph. Specifically, this directed graph must be a directed acyclic graph (DAG).
\item This constraint can be derived from 4, but so that it is not overlooked, we state the rule explicitly here: The \textit{endAction} cannot be a parent or ascendant of the \textit{startAction}
\end{enumerate}

If one of the constraints is not satisfied, the server will throw an error at workflow submission time.

\subsection{Actions}
Actions must have \textit{id}, \textit{name} and \textit{type} attributes. They have two optional boolean attributes: \textit{forceComputation} and \textit{isManaged}. If \textit{forceComputation} is set to \textit{True}, it means that the action will be forced to compute its output regardless of if its dataset  already exists in storage or not. If it is set to \textit{False}, it means that the system determines if the action will be computed or not. The default is \textit{False}.

If the attribute \textit{isManaged} is set to \textit{True}, it means that the path where the output of this action will be stored is determined and managed by the system. If \textit{isManaged} is set to \textit{False}, it means that the path where the output of this action will be stored is not determined or managed by the system, and that path must be provided by the user. The user needs to have Read/Write permissions to any path it provides, otherwise, the execution of the action will fail at the end. The default value for \textit{isManaged} is \textit{True}.

Notice also how action names do not need to be unique. An action name is just a mnemonic resource to understand what the action does. Also depending on the action type, there might be other required attributes too. We currently support three kinds of actions: \textbf{Command-line actions}, \textbf{MapReduce v1.0 actions} and \textbf{MapReduce v2.0 actions}, and in the future we are planning to add support for \textbf{Spark actions} and \textbf{Sqoop actions}

TODO: Explain how an action's dataset name is determined

\subsubsection{Command Line Action}
\subsubsection{MapReduce v1.0 Action}
\subsubsection{MapReduce v2.0 Action}

\section{The Action Manager}
The Action Manager's purpose is to submit individual actions to the Hadoop cluster for computation. In our current implementation it uses \textbf{Apache Oozie} as an intermediary, but there is nothing in the system that restricts us from doing away with \textbf{Apache Oozie} in the future.

On its current implementation, the Action Manager is ready to be distributed across different machines. That is, if there are multiple action managers running on different machines, they will not step up on each other toes, because they use the database as a mean of synchronization among them.

The Action Manager works as follows:

\begin{enumerate}
\item It maintains a synchronized queue Q with the actions that need to be submitted to the Hadoop cluster. The queue is capacity bounded and supports operations that wait for the queue to become non-empty when retrieving an element, and wait for space to become available in the queue when storing an element. All operations are thread safe.
\item The queue is filled by an \textbf{Action Scraper} entity that queries the database for actions that are ready to be submitted.
\item The \textbf{Action Manager} takes new actions from the queue and hands them to a pool of \textbf{Action Submitter} threads that will submit the actions to Hadoop and will also update the state of those actions in the database.
\end{enumerate}

\subsection{Action States}
In order to support a cluster of servers working as action managers and to avoid the need to add a dependency to a distributed coordination server such as \textbf{Apache Zookeper} we have implemented synchronization using the database as our shared resource and defining a synchronization oriented semantic for each of the different states an action can have.

An action can be in one of the following states: \textit{WAITING}, \textit{READY}, \textit{PROCESSING}, \textit{SUBMITTED}, \textit{RUNNING}, \textit{FINISHED}, \textit{FAILED}, and \textit{KILLED}.  (See Table \ref{tab:action_states} for a complete reference).

\begin{table}
\begin{tabular}{| l | p{12cm} |}

\hline
\textbf{Action State} & \textbf{Description} \\ \hline
WAITING & It means that the action has been submitted as part of a workflow and is waiting for parent actions to finish before it can be submitted to Hadoop.\\ \hline
READY & The action is ready to be submitted to Hadoop because it either does not depend on any other action, or because all the actions on which it depends have finished their computations. \\ \hline
PROCESSING & The ActionScraper found a READY action in the database and has placed it in the actions queue of the actions to be submitted. \\ \hline
SUBMITTED & The action has been taken from the queue and has been submitted to Hadoop. \\ \hline
RUNNING & Hadoop is running the computations that correspond to the action. \\ \hline
FINISHED & Hadoop has finished executing the action successfully.\\ \hline
FAILED & A run time error has occurred and the action did not finish executing.\\ \hline
KILLED & The user killed the action after it started executing.\\ \hline
\end{tabular}
\caption{Action State Descriptions.\label{tab:action_states}}
\end{table}

\subsection{The Action Scraper}
Every certain amount of time, the action scraper will query the database to find available actions and add them to the queue. Available actions are actions that are in the \textit{READY} state, or actions that have been in the \textit{PROCESSING} state for a long time. The reason why we add actions that have been in the \textit{PROCESSING} state for a long time is to account for the rare case where another \textbf{Action Manager} in another process started processing those actions, but because of some failure the process died before finish processing them.

Before adding the action to the queue, the action scraper attempts to update the state of the action in the database to \textit{PROCESSING}. If the update fails because the action entity has changed in the database after it was queried by the scraper, then the scraper drops the action and does not add it to the \textbf{Action Manager} queue. Otherwise, if the update is successful, the action is added to the \textbf{Action Manager} queue. To illustrate how this synchronization technique is valid, consider the following example with action scrapers $A$ and $B$ and their corresponding action managers. Both scrapers $A$ and $B$ query the database for ready actions and both find action $a1$ to be in the $READY$ state. Without loss of generality, assume that $A$ is the first scraper to update the state of action $a1$ to \textit{PROCESSING}. When $B$ also attempts to update the state of action $a1$, it will realize that action $a1$ has already been changed by someone else, and it will immediately drop it.

The synchronization technique described and exemplified in the above paragraph will be used multiple times by different components of the system. In general, that synchronization pattern can be applied in situations where multiple processes can potentially move an object $o$ from state $S1$ to state $S3$ (in the previous example $S1$ would be equivalent to our \textit{READY} state, and $S3$ to our \textit{SUBMITTED} state) but only one of the process should be allowed to do it. In order to solve the problem we create an intermediate state $S2$ (\textit{PROCESSING} in our case), and we let all the processes compete to be the first to change the state of $o$ to $S2$. All the loosing processes drop the processing of object $o$, and the winning process carries on.

\subsection{The Action Submitter}
The Action Manager is constantly taking new elements from the queue and passing them to the Action Submitter threads that take care of submitting the actions to Hadoop. The decision to include in the queue actions that have been in the \textit{PROCESSING} state for a long time makes the design of the Action Submitter more careful. The submitter first attempts to update the state of the action to \textit{SUBMITTED} in the database. If it succeeds, then it actually submits the action to Hadoop. If there is an error while submitting the action, then it changes the state of the action back to \textit{READY}, which gives that action the opportunity to be picked again by an \textbf{Action Scraper} at some point later on. As an area of future improvement, a ceiling should be imposed over the number of times an action fails when submitted to the cluster, otherwise, the system will keep trying to submit the action forever.

\section{The Workflow Manager}
Now that we have explained the \textbf{Action Manager}, we are in a better shape to understand the inner workings of the \textbf{Workflow Manager}. The \textbf{Workflow Manager} receives the workflows submitted to the system and determines which of the actions from the workflow need to actually be submitted to Hadoop for computation. Those actions are inserted into the database and can initially be in one of two states: \textit{WAITING} or \textit{READY}. If they are in a $READY$ state, any active \textbf{Action Manager} will pick them up and submit them to the cluster for computation. If they are in a $WAITING$ state they will eventually be submitted for execution once their parents finish executing. The process of how actions in the $WAITING$ state are notified that their parents finish executing will be discussed later when we discuss the \textbf{Callback System}.

\subsection{Datasets}
The \textbf{Workflow Manager} makes its decision on whether an action needs to be computed or not by exploring the state of the datasets that are the outputs of the action. A dataset is another important entity in our model. A dataset entity is an entry of a dataset information in the database; its dataset file is the physical file in the distributed file system. A dataset entry is always linked in the database to its corresponding action definition. Dataset entities can be in one of the following states at any given time: \textit{TO\_DELETE}, \textit{TO\_STORE}, \textit{TO\_LEAF}, \textit{STORED}, $LEAF$, $STORED\_TO\_DELETE$, $PROCESSING$, $DELETING$ and $DELETED$. (See Table \ref{tab:dataset_states} for a complete reference).

\begin{table}
\begin{tabular}{| l | p{12cm} |}
\hline
\textbf{Dataset State} & \textbf{Description} \\ \hline
TO\_DELETE & The dataset file does not exist in the file system, but once it does, its dataset entry will be transitioned to state STORED\_TO\_DELETE. \\ \hline
TO\_STORE & The dataset file does not exist in the file system, but once it does, its dataset entry state will be transitioned to STORED. \\ \hline
TO\_LEAF & The dataset file does not exist yet in the file system, but once it does, its dataset entry state will be transitioned to the LEAF state. \\ \hline
STORED & The dataset file is stored in the filesystem and it corresponds to an intermediate action. The dataset file will be stored in the file system until the decision algorithm determines in the future that is not optimal for the system to keep storing it anymore. \\ \hline
LEAF & The dataset file is stored in the filesystem and it corresponds to a leaf action. Datasets of leaf actions are never removed by the system. They can be manually removed by the users. \\ \hline
STORED\_TO\_DELETE & The dataset file is stored temporarily until all other actions that have claims to it as a dependency finish computing. Once all those actions finish computing, the dataset will be removed. \\ \hline
PROCESSING & The dataset entry is being processed with the purpose of deleting its dataset file. This is a synchronization state. \\ \hline
DELETING & The dataset file is being deleted. This is another synchronization state. \\ \hline
DELETED & The dataset file has been deleted. \\ \hline
\end{tabular}
\caption{Dataset State Descriptions.\label{tab:dataset_states}}
\end{table}

The \textbf{Workflow Manager} processes all the actions of the submitted workflow, \textbf{starting from the leaf actions} in a Breadth-First-Search (BFS) manner If by analyzing the action it determines that the action needs to be computed, it calls the \textit{prepareForComputation} procedure on that action.  The \textit{prepareForComputation} procedure first creates an action object $P$ in the \textit{WAITING} state and inserts it to the database. Also, for each children $C$ of action $P$ that also needs to be computed, the system marks on the database that $C$ is depending on $P$, so that $C$ will need to wait for P output dataset before being ready to be computed. At last, the procedure adds all the parents of the action P to the queue if they have not already being added.

The \textbf{Workflow Manager} makes the determination if an action needs to be computed as described in Algorithm \ref{alg:workflow_manager}

\begin{algorithm}
\begin{singlespace}
\caption{Workflow Manager Algorithm}
\label{alg:workflow_manager}
\begin{algorithmic}[1]
\Procedure{WorkflowManager}{Q, W}
\State $A \gets Q.pop()$ \Comment{$A$ is the next action to be processed}
\If {A.isManaged==False \textbf{OR} A.forceComputation == True}
	\State $prepareForComputation(A)$
\Else
	\State $D \gets dataset(A)$ \Comment{$D$ is the dataset that corresponds to $A$}
	\If {D == null OR D.state is one of [DELETED, DELETING, PROCESSING, TO\_DELETE, STORED\_TO\_DELETE]}
		\State $prepareForComputation(A)$
	\Else
		\If {D.state is one of [STORED, LEAF]}
			\If {A is a leaf action but D.state == STORED}
				\State $D.state \gets LEAF$ \Comment{In this way the dataset cannot now be marked to be deleted by the Decision Algorithm.}
				
			\EndIf
			
			\For{each child C of action A}
				\If {C was marked for computation when processed}
					\State $addClaim(C, D)$ \Comment{Marks in database that action C depends on D.  No dataset can be deleted if it has a pending claim.}		
					\If {addClaim(C, D) fails because D.state has changed}
						\State $prepareForComputation(A)$
					\EndIf
				\EndIf
			
			\EndFor
		\Else
			\If {D.state is in [TO\_STORE or TO\_LEAF]}
				\State $prepareForComputation(A)$
			\EndIf
		\EndIf
	\EndIf
\EndIf
\EndProcedure
\end{algorithmic}
\end{singlespace}
\end{algorithm}

I want to call the attention to three different behaviors of the algorithms described above. First, on the \textit{prepareForComputation} procedure, the system marks on the database that an action C is depending on an action $P$. This is needed so that the \textbf{Callback Mechanism} (which will be described later) can find which are the actions depending on action $P$ when action $A$ finishes computing.

Secondly, on the Workflow Manager algorithm, notice how there is a command described as $addClaim(C, D)$. What this does is to add a claim from child C to the dataset entity D in the database, so that the Dataset Deletor system (to be described later) do not delete a dataset D while there is an action that depends on it that has not been computed yet.

Thirdly, for the sake of correctness of the overall state of the system, we have introduced an inefficiency in the Workflow Manager's algorithm. Notice that if a dataset $D$ is in $TO\_STORE$ or $TO\_LEAF$ state, we still prepare action $A$ for computation. A dataset $D$ is in $TO\_STORE$ or $TO\_LEAF$ state if its corresponding action is currently computing given dataset. This means that some other workflow submitted to the system is currently computing dataset $D$. To make the system more efficient, instead of asking the system to recompute action $A$, we could make all the children actions of $A$ to depend on $A'$ (the sibling action of $A$ from another workflow), and add a claim from the child actions of $A$ to dataset $D$. The problem with this approach is that both action $A'$ and dataset $D$ could be having their states changed to something contrary to the current situation at the same time we are planning to change the state of the children of action $A$ with outdated information on the states of $A'$ and $D$. Trying to handle that situation would mean that we need to introduce more complex synchronization mechanisms across multiple components of the system. For now we think that the benefits of simplicity will outweight the efficiency gains of trying to improve a situation that we consider will happen rarely.

\section{The Callback System}
Once an action is submitted, three callbacks are provided to the Hadoop cluster so that it can notify back to the system of any relevant event regarding the execution of the action by the cluster. All callbacks are designed in such a way that the state of the action is always the same after multiple calls to the same callback.

\subsection{The Success Callback}
The first thing the success callback does is to change from $WAITING$ to $READY$ the state of any child actions of the currently finished action that are not waiting for any other parent action to finish. It also changes the state of the currently finished action to $FINISHED$. The callback also removes any claims the currently finished action may have had over datasets. The callback finally updates the state and metadata of the dataset outputted by the currently finished action: dataset state is changed from $TO\_STORE$, $TO\_LEAF$ or $TO\_DELETE$ to $STORED$, $LEAF$ or $STORED\_TO\_DELETE$ accordingly. Also, the size the dataset occupies in the filesystem is also updated on its entry in the database. That size is an important factor used by the optimization algorithm.

\subsection{The Action Failed Callback}
The action failed callback is simpler than the success callback. It removes any claims that the failed action may have had over any datasets. If the action that failed produced any output or partial output, its state is changed to $STORED\_TO\_DELETE$ regardless of the previous state of the dataset. Also, the state of the action itself is changed to $FAILED$.

\subsection{The Action Killed Callback}
The action killed callback removes any claims that the killed action may have had over any datasets. If the action that was killed produced any output or partial output, its state is changed to $STORED\_TO\_DELETE$ regardless of the previous state of the dataset. Also, the state of the action itself is changed to $KILLED$.

\section{The Dataset Manager}
The dataset manager takes care of handling the deletion of datasets from the file system. Its archicture is similar to the architecture of the Action Manager:

\begin{enumerate}
\item The Dataset Manager maintains a synchronized queue Q with the datasets that need to be deleted from the cluster. The queue is capacity bounded and supports operations that wait for the queue to become non-empty when retrieving an element, and wait for space to become available in the queue when storing an element. All operations are thread save.
\item The queue is filled by a DatasetScraper entity that queries the database for datasets ready to be deleted.
\item The Dataset Manager takes dataset entries inserted to the queue and hands them to a pool of Dataset Deletor threads that will take care of removing the datasets from the cluster and updating the state of those datasets in the database.
\end{enumerate}

\subsection{The Dataset Scraper}
Every certain time, the dataset scraper will query the database to find available datasets to be deleted and add them to the queue. Datasets to delete are such that are in the $STORED\_TO\_DELETE$ state, or datasets that have been in the $DELETING$ or $PROCESSING$ state for a long time. The reason why we add datasets that have been in the $DELETING$ or $PROCESSING$ state for a long time is to account for the rare case where another DatasetManager in another process could have began processing those actions, but that process died before finish processing them.

Before adding the dataset to the queue, the dataset scraper attempts to update the state of the dataset in the database to $PROCESSING$. If the update fails because the dataset entity has changed in the database after it was queried by the scraper, then the scraper drops the dataset and does not add it to the Dataset Manager queue. Otherwise, if the update is successful, the action is added to the Dataset Manager queue.

\subsection{The Dataset Deletor}
The Dataset Manager is constantly taking new elements from the queue and passing them to the Dataset Deletor threads that take care of removing the datasets from the file system. The deletor first attempts to update the state of the dataset to $DELETING$. If it succeeds, then it actually deletes the dataset from the file system and updates its state to $DELETED$. If it does not succeed, or if some other error occurs while deleting so that it cannot delete, it changes the state of the dataset back to $STORED\_TO\_DELETE$ and stops processing it.

\section{The Decision Manager}
The Decision Manager is the piece of the system that determines which of the datasets currently stored in the system should be deleted. The manager has three main components that work together: A file system utility that determines how much space is available at the time, an Action Rolling Window system and a Decision Algorithm. The Decision Manager is implemented in such a way that the decision algorithm is a plug and play piece that can be substituted, with different algorithms optimizing for different evaluation metrics.

The first thing that happens is that the Decision Manager queries the file system utility to obtain the amount of space currently in use by the datasets managed by the system. If the space exceeds a certain threshold, then the decision engine fires up its process:

\begin{enumerate}
\item First it obtains a list of the last N submitted actions to the system from the Action Rolling Window. Using this list of actions, it then rebuilds the graph of the workflows to which this actions belonged too in a special datastructure that we call simplified workflow history.
\item We pass the simplified workflow history that comprises the last N submitted actions to the decision algorithm, together with the amount of space that we need to free, and the decision algorithm returns a list of datasets that need to be deleted. The sum of the storage space of the returned datasets will be at least the amount of space that needs to be freed.
\item The Decision Manager changes the state of the datasets returned by the decision algorithm to $STORED\_TO\_DELETE$, leaving in the hands of the Dataset Manager the actual execution of the deletion of the datasets.

\end{enumerate}

\section{The Decision Algorithms}
All the decision algorithms implement the same interface.  They take two parameters as input: a datastructure that we have called $Simplified Workflow History$ ($SWH$), and the space to free ($spaceToFree$).  The Simplified Workflow History provides a very generic API that makes it easy to gather statistics on the history of workflows.
So far we have implemented two decision algorithms in Pingo: a most-commonly-used decision algorithm, and an adaptive algorithm.

\subsection{Most Valuable Algorithm Family}
This is a very simple algorithm that represents a big family of possible algorithms that can be implemented.  The idea is to retain in storage the datasets with the most value.  Implementations of this base algorithm need to define what value is.  For example, in Algorithm \ref{alg:most_commonly_used_decision} we have defined value as simply the number of times the dataset is used throughout the history of workflows. This is a very simple definition of value, but provides the most straightforward implementation.  Algorithm \ref{alg:most_commonly_used_decision} is valuable as a baseline to compare against.

\begin{algorithm}
\begin{singlespace}
\caption{Most-Commonly-Used Algorithm}
\label{alg:most_commonly_used_decision}
\begin{algorithmic}[1]
\Procedure{MostCommonlyUsed}{$SWH, spaceToFree$}
	\State $datasetCounts \gets SWH.datasetCounts()$
	\State $sortedDatasetCounts \gets sortByCount(datasetCounts)$
	\State $spaceFred \gets 0$
	\State $toDelete \gets List()$
	\For{$count$, $dataset$ in $datasetCounts$}
		\If{$spaceFred \geq spaceToFree$}
			\State \textbf{break}
		\EndIf	
		\State $toDelete.append(dataset)$
		\State $spaceFred \gets spaceFred + dataset.space$
	\EndFor
	
	\State \textbf{return} $toDelete$
\EndProcedure
\end{algorithmic}
\end{singlespace}
\end{algorithm}

\subsection{Simple Adaptive Algorithm Family}
Algorithms that belong to the $Most Valuable Algorithm$ family are a good starting point, but they have a weakness: they treat the entire history of workflows in the same way.  This is troublesome, specially if it is the case that most recent datasets are more likely to be used than less recent ones.  The main question that we need to be asking is: How far back into the history of workflows do we need to look to determine the value of datasets? This is a difficult question to answer, and finding good answers for it is an area of further research.  We propose a simple adaptive algorithm, described in Algorithm \ref{alg:adaptive_most_commonly_used_decision} that looks to the entire history of workflows to determine some statistics on how far back do workflows usually look back when reusing datasets. Then we call the corresponding procedure from the \textbf{Most Valuable Algorithm Family} in order to determine the datasets to delete in this smaller workflow history.

\begin{algorithm}
\begin{singlespace}
\caption{Adaptive Most-Commonly-Used Algorithm}
\label{alg:adaptive_most_commonly_used_decision}
\begin{algorithmic}[1]
\Procedure{AdaptiveMostCommonlyUsed}{$SWH, spaceToFree$}
	\State $recencyList \gets List()$
	\State $n \gets length(SWH)$
	\For{$i$ in from 1 to $n$}
		\For{dataset $d$ in $W_i$}
			\State $W_j \gets$ previous workflow where d was used.
			\If{$W_j$ \textbf{is not} $Null$}
				\State $recencyList.append(i - j)$
			\EndIf
		\EndFor
			
	\EndFor
	\State $\mu \gets mean(recencyList)$
	\State $\sigma \gets std(recencyList)$
	\State $smallerHistory \gets SWH.subList(n - \mu - 2\sigma, n + 1)$
	\State \textbf{return} $MostCommonlyUsed(smallerHistory, spaceToFree)$

\EndProcedure
\end{algorithmic}
\end{singlespace}
\end{algorithm}





